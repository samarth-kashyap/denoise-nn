{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Setting device to CUDA if gpu is available, else setting device to CPU\n",
    "# GPU availability can be checked using torch.cuda.is_available() function call\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "transform = transforms.ToTensor() # convert data to torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disk2/samarth/denoise-nn\n"
     ]
    }
   ],
   "source": [
    "cd ~/denoise-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom npy loader\n",
    "def npy_loader(path):\n",
    "    sample = torch.from_numpy(np.load(path).astype('float32'))\n",
    "    return sample\n",
    "\n",
    "train_dataset_noisy = datasets.DatasetFolder(\n",
    "    root='train-set/noisy',\n",
    "    loader=npy_loader,\n",
    "    extensions=['.npy']\n",
    ")\n",
    "\n",
    "train_dataset_target = datasets.DatasetFolder(\n",
    "     root='train-set/target',\n",
    "     loader=npy_loader,\n",
    "     extensions=['.npy']\n",
    ")\n",
    "\n",
    "test_dataset_noisy = datasets.DatasetFolder(\n",
    "    root='test-set/noisy',\n",
    "    loader=npy_loader,\n",
    "    extensions=['.npy']\n",
    ")\n",
    "\n",
    "test_dataset_target = datasets.DatasetFolder(\n",
    "     root='test-set/target',\n",
    "     loader=npy_loader,\n",
    "     extensions=['.npy']\n",
    ")\n",
    "\n",
    "# Using a wrapper to create custom dataset\n",
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, ds_noisy, ds_target):\n",
    "        self.ds_noisy = ds_noisy\n",
    "        self.ds_target = ds_target\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        xA = self.ds_noisy[index]\n",
    "        xB = self.ds_target[index]\n",
    "        return xA, xB\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DenoisingDataset(train_dataset_noisy, train_dataset_target)\n",
    "test_dataset = DenoisingDataset(test_dataset_noisy, test_dataset_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test dataloaders\n",
    "num_workers = 0  # number of subprocesses to use for data loading\n",
    "batch_size = 30  # how many samples per batch to load\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearAutoencoder(\n",
      "  (encoder1): Linear(in_features=500, out_features=250, bias=True)\n",
      "  (encoder2): Linear(in_features=250, out_features=125, bias=True)\n",
      "  (encoder3): Linear(in_features=125, out_features=64, bias=True)\n",
      "  (decoder1): Linear(in_features=64, out_features=125, bias=True)\n",
      "  (decoder2): Linear(in_features=125, out_features=250, bias=True)\n",
      "  (decoder3): Linear(in_features=250, out_features=500, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(LinearAutoencoder, self).__init__()\n",
    "        ## encoder ##\n",
    "        self.encoder1 = nn.Linear(500, 250)\n",
    "        self.encoder2 = nn.Linear(250, 125)\n",
    "        self.encoder3 = nn.Linear(125, encoding_dim)\n",
    "\n",
    "        ## decoder ##\n",
    "        self.decoder1 = nn.Linear(encoding_dim, 125)\n",
    "        self.decoder2 = nn.Linear(125, 250)\n",
    "        self.decoder3 = nn.Linear(250, 500)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define feedforward behavior \n",
    "        # and scale the *output* layer with a sigmoid activation function\n",
    "        # pass x into encoder\n",
    "        out = F.relu(self.encoder1(x))\n",
    "        out = F.relu(self.encoder2(out))\n",
    "        out = F.relu(self.encoder3(out))\n",
    "        \n",
    "        # pass out into decoder\n",
    "        out = torch.sigmoid(self.decoder1(out))\n",
    "        out = torch.sigmoid(self.decoder2(out))\n",
    "        out = torch.sigmoid(self.decoder3(out))\n",
    "        return out\n",
    "\n",
    "# initialize the NN\n",
    "encoding_dim = 64\n",
    "model = LinearAutoencoder(encoding_dim)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# define the NN architecture\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mConvAutoencoder\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(ConvAutoencoder, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# define the NN architecture\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        #Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  \n",
    "        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "       \n",
    "        #Decoder\n",
    "        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 3, 2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        x = F.sigmoid(self.t_conv2(x))    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss() # specify loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # specify optimizer function\n",
    "\n",
    "import os\n",
    "os.system('ls train-set/metadata*.pkl > pkl_name')\n",
    "with open('pkl_name', 'r') as f:\n",
    "    metadata_file = f.read().splitlines()\n",
    "fsuffix = metadata_file[0].split('/')[-1][9:-4]\n",
    "os.system('rm pkl_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Training Loss: 0.022277  Testing Loss: 0.022190\n",
      "Epoch: 2  Training Loss: 0.002464  Testing Loss: 0.002485\n",
      "Epoch: 3  Training Loss: 0.001769  Testing Loss: 0.001808\n",
      "Epoch: 4  Training Loss: 0.001550  Testing Loss: 0.001597\n",
      "Epoch: 5  Training Loss: 0.001443  Testing Loss: 0.001492\n",
      "Epoch: 6  Training Loss: 0.001373  Testing Loss: 0.001414\n",
      "Epoch: 7  Training Loss: 0.001334  Testing Loss: 0.001382\n",
      "Epoch: 8  Training Loss: 0.001294  Testing Loss: 0.001349\n",
      "Epoch: 9  Training Loss: 0.001264  Testing Loss: 0.001331\n",
      "Epoch: 10  Training Loss: 0.001243  Testing Loss: 0.001308\n",
      "Epoch: 11  Training Loss: 0.001225  Testing Loss: 0.001287\n",
      "Epoch: 12  Training Loss: 0.001201  Testing Loss: 0.001266\n",
      "Epoch: 13  Training Loss: 0.001184  Testing Loss: 0.001255\n",
      "Epoch: 14  Training Loss: 0.001175  Testing Loss: 0.001243\n",
      "Epoch: 15  Training Loss: 0.001158  Testing Loss: 0.001231\n",
      "Epoch: 16  Training Loss: 0.001144  Testing Loss: 0.001210\n",
      "Epoch: 17  Training Loss: 0.001138  Testing Loss: 0.001212\n",
      "Epoch: 18  Training Loss: 0.001133  Testing Loss: 0.001207\n",
      "Epoch: 19  Training Loss: 0.001125  Testing Loss: 0.001209\n",
      "Epoch: 20  Training Loss: 0.001103  Testing Loss: 0.001180\n",
      "CPU times: user 1h 39min 57s, sys: 45min 45s, total: 2h 25min 42s\n",
      "Wall time: 48min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    len_testloader = 0\n",
    "    for data in train_loader:\n",
    "        # _ stands in for labels, here\n",
    "        noisy, target = data\n",
    "        noisy = noisy[0]\n",
    "        target = target[0]\n",
    "        \n",
    "        tnoisy, ttarget = next(enumerate(test_loader))[1]\n",
    "        tnoisy = tnoisy[0]\n",
    "        ttarget = ttarget[0]\n",
    "        tnoisy = tnoisy.to(device)\n",
    "        ttarget = ttarget.to(device)\n",
    "        toutput = model(tnoisy)\n",
    "        tloss = criterion(toutput, ttarget)\n",
    "        test_loss += tloss.item()*tnoisy.size(0)\n",
    "        len_testloader += 1\n",
    "        \n",
    "        # converting to device array\n",
    "        noisy = noisy.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(noisy)\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*noisy.size(0)\n",
    "        \n",
    "            \n",
    "    # print avg training statistics \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    test_loss = test_loss/len_testloader\n",
    "    print('Epoch: {:02d}  Training Loss: {:.6f}  Testing Loss: {:.6f}'.format(epoch, train_loss, test_loss))\n",
    "    \n",
    "    if epoch > 14:\n",
    "        torch.save(model.state_dict(), f'train-set/model-{epoch}-{fsuffix}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "diter = iter(train_loader)\n",
    "diter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     a, b \u001b[38;5;241m=\u001b[39m \u001b[43mditer\u001b[49m\u001b[38;5;241m.\u001b[39mnext()\n\u001b[1;32m      3\u001b[0m nnop \u001b[38;5;241m=\u001b[39m model(a[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m      5\u001b[0m freq \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m1400\u001b[39m, \u001b[38;5;241m1450\u001b[39m, \u001b[38;5;241m500\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'diter' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    a, b = diter.next()\n",
    "nnop = model(a[0][10].to(device))\n",
    "\n",
    "freq = np.linspace(1400, 1450, 500)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(freq, a[0][10], 'b', alpha=0.3, label='data')\n",
    "plt.plot(freq, nnop.cpu().detach(), 'r', label='Prediction')\n",
    "plt.plot(freq, b[0][10], 'k', label='True')\n",
    "plt.xlabel('Frequency in $\\mu$Hz')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'train-set/model-{fsuffix}.pth')\n",
    "\n",
    "# saved model can be loaded using\n",
    "# encoding_dim = 32\n",
    "# model = LinearAutoencoder(encoding_dim)\n",
    "# model.load_state_dict(torch.load(f'train-set/model-{fsuffix}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(5):\n",
    "    n_epochs = i+15\n",
    "    _model = LinearAutoencoder(encoding_dim)\n",
    "    _model.load_state_dict(torch.load(f'train-set/model-{n_epochs}-{fsuffix}.pth'))\n",
    "    models.append(_model.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    a, b = diter.next()\n",
    "\n",
    "nnops = []\n",
    "for i in range(5):\n",
    "    nnop = models[i](a[0][10].to(device))\n",
    "    nnops.append(nnop)\n",
    "\n",
    "freq = np.linspace(1400, 1450, 500)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(freq, a[0][10], 'b', alpha=0.3, label='data')\n",
    "\n",
    "for i in range(5): plt.plot(freq, nnops[i].cpu().detach(), \n",
    "                            'r', alpha=0.6, label='Prediction')\n",
    "\n",
    "plt.plot(freq, b[0][10], 'k', label='True')\n",
    "plt.xlabel('Frequency in $\\mu$Hz')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
